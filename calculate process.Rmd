---
title: "p8105_hw5_zx2425"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(htmlwidgets)
library(flexdashboard)
library(p8105.datasets)
library(rvest)
library(readxl)
```

# Problem2
## step1
Describe the raw data. Create a city_state variable (e.g. “Baltimore, MD”) 

```{r}
hmcd =read.csv("./homicide-data.csv") %>% 
  janitor::clean_names() 
head(hmcd)
```
The data set has `r nrow(hmcd)` * ` r ncol(hmcd)` dimensions. Where uid describes the incident number, reported_date indicates the date and time, victim_last and victim first indicates the victim's name, and other data includes: race, age, gender, city, state, longitude, and latitude. And whether the incident was finally detected.

## step2
then summarize within cities to obtain the total number of homicides and the number of unsolved homicides (those for which the disposition is “Closed without arrest” or “Open/No arrest”).

```{r}
hmcd=hmcd %>% 
  mutate(
    city_state=str_c(city,"_",state)
  )

count_vic=hmcd %>% 
  group_by(city_state) %>% 
  summarize(
    vic_number=n()
  )
count_dect=hmcd %>% 
  filter(disposition %in% c("Closed without arrest", "Open/No arrest")) %>% 
  group_by(city_state) %>% 
  summarize(
    undec_number=n()
  )

count = full_join(count_vic,count_dect,by="city_state")
count[is.na(count)] = 0
```

## step3
For the city of __Baltimore, MD__, use the __prop.test__ function to estimate the proportion of homicides that are unsolved; save the output of prop.test as an R object, apply the __broom::tidy__ to this object and pull the _estimated_ _proportion_ and _confidence intervals_ from the resulting tidy dataframe.

```{r}
city_B= hmcd %>% 
  filter(city_state == 'Baltimore_MD')
city_B_count= city_B %>% 
   summarise(
      unsolved = sum(disposition %in%c("Closed without arrest", "Open/No arrest")  ),
      ###sum can calculate the True or false with result of number
      n = n()
    )
city_B_test = 
  prop.test(x = city_B_count %>% pull(unsolved),n = city_B_count %>% pull(n))
city_B_test %>% 
  broom::tidy() %>% 
  knitr::kable()  
  
```
## step4
Now run __prop.test__ for _each of the cities_ in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Do this within a “tidy” pipeline, making use of __purrr::map, purrr::map2__, list columns and __unnest__ as necessary to create a tidy dataframe with _estimated proportions and CIs_ for each city.

```{r}
pro_test_df= function(each_city){
  city_info=
    each_city %>% 
    summarize(
      unsolved = sum(disposition %in%c("Closed without arrest", "Open/No arrest")  ),
      n=n()
    )
  city_test= prop.test(
    x=city_info %>% pull(unsolved),
    n=city_info %>% pull(n)
  )
  city_test
}
```

```{r}
hmcd %>% 
  filter(city_state == 'Albuquerque_NM') %>% 
  pro_test_df() %>% 
  broom::tidy() %>% 
  knitr::kable()

city_iterate = 
  hmcd %>% 
    nest(-city_state) %>% 
    mutate(
      test_results = map(data, pro_test_df),
      ##???
      tidy_results = map(test_results, broom::tidy)
    ) %>% 
    select(city_state, tidy_results) %>% 
    unnest(tidy_results) %>%
    ##~~~
    select(city_state, estimate, starts_with('conf'))
    ##!!!
city_iterate
```
## step5
Create a plot that shows the estimates and CIs for each city – check out geom_errorbar for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.
```{r}
city_iterate %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high))
```
By observing the plote, we can see there is a extreme data which is Tulsa_AL, we delete it can replot again.
```{r}
city_iterate = city_iterate %>% 
  filter(city_state !="Tulsa_AL")
city_iterate %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high))
```
# problem3
When designing an experiment or analysis, a common question is whether it is likely that a true effect will be detected – put differently, whether a false null hypothesis will be rejected. The probability that a false null hypothesis is rejected is referred to as power, and it depends on several factors, including: the sample size; the effect size; and the error variance. In this problem, you will conduct a simulation to explore power in a one-sample t-test.

# step1
Let's define a t.test function with known parameter
```{r}
t_test  = function(mu, n=30, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma),
  )
  
   t_result = t.test(sim_data) %>% 
    broom::tidy() %>% 
    select(estimate,p.value)
  t_result
}

```
## Step=2
Let's simulate when u=0
```{r}
t_test(0)
sim_results_df = 
  expand_grid(
    mean_1 = 0,
    iter = 1:5000
  ) %>% 
  mutate(
    t_result = map(mean_1,t_test)
  ) %>% 
  unnest(t_result)

```

## step=3
Let's simulate when u=1:6
```{r}
mean_16 = expand_grid(mean_16 = 1:6, iteration = 1:5000) %>% 
  mutate(t_result = map(mean_16,t_test))
mean_16result = mean_16 %>%   
unnest(t_result)
mean_16result
mean_16result= na.omit(mean_16result) 
```
## step4
Make a plot showing the __proportion of times the null was rejected__ (the power of the test) on the y axis and the true value of μ on the x axis. Describe the association between effect size and power.
Let's us observe when u is equal to different value, the proportion of times that we reject H0
```{r}
plot1_df=mean_16result %>% 
  group_by(mean_16) %>% 
  summarize(
    reject_case=sum(p.value<0.05),
    reject_proportion=reject_case/5000
  )

plot1=plot1_df %>% 
  ggplot(aes(x=mean_16,y=reject_proportion))+
    scale_x_continuous(limits=c(1,6),breaks=seq(1,6,11))+
      geom_point()+
      geom_path()
plot1
```
With the total number of the case increase, the reject proportion increase at the same time. Furthermore, the trend of the value change is tend to be 1.

## step5
Make a plot showing the average estimate of μ^ on the y axis and the true value of μ on the x axis. 
```{r}
mean_16result %>%
  group_by(mean_16) %>% 
  summarize(avg_eti = mean(estimate)) %>% 
  ggplot(aes(x = mean_16,y = avg_eti)) +
  scale_x_continuous(limits = c(1,6), breaks = seq(1,6,1)) + 
  geom_point() + 
  geom_path()
```

## step 6
Make a second plot (or overlay on the first) the average estimate of μ^ only in samples for which the null was rejected on the y axis and the true value of μ on the x axis. Is the sample average of μ^ across tests for which the null is rejected approximately equal to the true value of μ? Why or why not?
```{r}
rej_eti_u = mean_16result %>% 
  filter(p.value < 0.05) %>% 
  group_by(mean_16) %>% 
  summarize(
    avg_eti = mean(estimate))
plot2=rej_eti_u %>% 
  ggplot(aes(x = mean_16,y = avg_eti)) +
  scale_x_continuous(limits = c(1,6), breaks = seq(1,6,1)) + 
  geom_point() + 
  geom_path()
plot2


```

